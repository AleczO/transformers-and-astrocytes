{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0350f0",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "A __Hopfield network__ consists of $N$ fully connected neurons. The model states __evolve__ in time with time steps $\\Delta t$ (here it's assumed that $\\Delta t = 1$).\n",
    "\n",
    "\n",
    "The __state__ of the netwok at time $t$ is denoted by a vector\n",
    "\n",
    "$$ \\mathbf{S}(t) = \\{ S_1 (t), \\ S_2(t), \\ \\dots, S_N(t) \\} $$\n",
    "\n",
    "where each state has __two possible states__ $S_i(t) \\in \\{-1, 1\\}, \\forall i \\in \\{1, \\dots, N \\}$. \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Neurons interact with each other with weights $w_{i,j}$, where $i, j \\in \\{1, \\dots, N \\}$. These weights can be expressed as matrix $\\mathbf{W} \\in \\mathbb{R}^{N \\times N}$.\n",
    "\n",
    "\n",
    "The state $s_i$ of each neuron is __updated with rule__\n",
    "\n",
    "$$\n",
    "S_i(t + 1) = \\text{sgn}[h_i(t)] =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } h_i(t) > 0 \\\\\n",
    "S_i(t) & \\text{if } h_i(t) = 0 \\\\\n",
    "-1 & \\text{if } h_i(t) < 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "with \n",
    "\n",
    "$$ h_i(t) = \\sum_{j=1}^N w_{ij} S_j(t) - \\theta $$\n",
    "\n",
    "with $\\theta = 0$\n",
    "\n",
    "In the standard model, __asynchronous updates__ are used to ensure the network reaches a stable configuration $\\mathbf{S}(t + 1) = \\mathbf{S}(t)$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c85688",
   "metadata": {},
   "source": [
    "# Patterns in Hopfield Network\n",
    "\n",
    "A Hopfield Network acts as __associative memory__ where stored __patterns__ are represented as a __set of neuron configurations__ $\\mathbf{p}^{(\\mu)} \\in \\{-1, 1\\}^N, \\mu \\in \\{1, \\dots, M \\}$. The network dynamics are designed such that these patterns become __attractors__ in the state space.\n",
    "\n",
    "\n",
    "Gievn an initial setup $\\mathbf{S}(t = 0) = \\mathbf{p}$ (a distorted version of $\\mathbf{p}^{(\\mu)}$), the system evolves over time $t$ such that:\n",
    "\n",
    "$$ \\lim_{t \\rightarrow \\infty} \\mathbf{S}(t) = \\mathbf{p}^{(\\mu)} $$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ede69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1.  1. -1.  1.  1.  1.  1.]\n",
      " [-1. -1.  1. -1.  1.  1. -1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "N = 8\n",
    "M = 2\n",
    "\n",
    "T = np.zeros((M, N))\n",
    "\n",
    "for i in range(M):\n",
    "    for j in range(N):\n",
    "        T[i][j] = random.choice([-1, 1])\n",
    "\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249afe97",
   "metadata": {},
   "source": [
    "To store $M$ patterns in the network, the weights are determined using a __Hebbian learning rule__. The weight $w_{ij}$ represents the association between neurons $i$ and $j$ across all stored patterns\n",
    "\n",
    "$$ w_{ij} = c\\sum_{\\mu=1}^M p_i^{(\\mu)} p_j^{(\\mu)}, \\ \\ \\ \\ \\ c \\in \\mathbb{R}^+, \\ \\forall i, j \\in {1, \\dots, N} $$\n",
    "\n",
    "\n",
    "In matrix form, this is represented as the sum of the __outer products__ of all pattern vectors\n",
    "\n",
    "$$ \\mathbf{W} = c \\sum_{\\mu=1}^M \\mathbf{p}^{(\\mu)}[\\mathbf{p}^{(\\mu)}]^T $$\n",
    "\n",
    "\n",
    "standard choice of the constant $c$ is $c=1/N$.\n",
    "\n",
    "\n",
    "To ensure the network does not coverge to trivial solution and to maintain the properties of a Energy function, we enforce:\n",
    "1. __Symmetry__: $w_{ij} = w_{ji}$ (property of $\\mathbf{x}\\mathbf{x}^T$)\n",
    "2. __No self connection__: $w_{ii} = 0, \\ \\forall i$ \n",
    "\n",
    "The modified weight matrix satisfying these constraints is: \n",
    "\n",
    "$$ \\mathbf{W} = \\frac{1}{N} \\sum_{\\mu=1}^M \\big( \\mathbf{p}^{(\\mu)}[\\mathbf{p}^{(\\mu)}]^T - \\mathbf{I} \\big) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d084574d",
   "metadata": {},
   "source": [
    "# Pattern Retrieval\n",
    "\n",
    "The measure of similarity between current state $\\mathbf{S}(t)$ and pattern $\\mathbf{p}^{(\\mu)}$ is calculated using __overlap parameter__ (magnetization):\n",
    "\n",
    "$$ m^{(\\mu)} (t) =  \\frac{1}{N} \\sum_{i = 1}^N p_i^{(\\mu)} S_i(t) =  \\frac{1}{N} [\\mathbf{p}^{(\\mu)}]^T \\mathbf{S}(t)  $$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "We can analyze the local field $h_i(t)$ in terms of these overlaps. Substituting the Hebbian weights:\n",
    "\n",
    "$$ h_i(t) = \\sum_{j=1}^N w_{ij} S_j(t) = \\sum_{j=1}^N \\left( c\\sum_{\\nu=1}^M p_i^{(\\nu)} p_j^{(\\nu)} \\right) S_j(t) $$\n",
    "\n",
    "Rearranging the summation order:\n",
    "\n",
    "$$h_i(t) = cN\\sum_{\\nu=1}^M p_i^{(\\nu)} \\underbrace{\\left( \\frac{1}{N} \\sum_{j=1}^N p_j^{(\\nu)} S_j(t) \\right)}_{m^{(\\nu)}(t)}$$\n",
    "\n",
    "\n",
    "$$ h_i(t) = cN \\sum_{\\nu = 1}^M p_i^{(\\nu)} m^{(\\nu)}(t)$$\n",
    "\n",
    "Note that the above calculation naturally implies $c = 1/N$ to ensure the local field remains independent of the network size $N$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
